{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset, Subset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms, models, utils\n",
        "from torchvision.transforms import ToTensor\n",
        "import numpy as np "
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "import logging\n",
        "from azureml.core import Workspace, Experiment, Dataset\n",
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget"
      ],
      "outputs": [],
      "execution_count": 58,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace(\"4b134a83-eb22-46e0-b44d-696615a1e373\", \"GSN\", \"GSN-Projekt\")"
      ],
      "outputs": [],
      "execution_count": 59,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip install seaborn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: seaborn in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (0.11.2)\nRequirement already satisfied: scipy>=1.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from seaborn) (1.5.2)\nRequirement already satisfied: numpy>=1.15 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from seaborn) (1.18.5)\nRequirement already satisfied: matplotlib>=2.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from seaborn) (3.2.1)\nRequirement already satisfied: pandas>=0.23 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from seaborn) (0.25.3)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\nRequirement already satisfied: python-dateutil>=2.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\nRequirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\nRequirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pandas>=0.23->seaborn) (2021.3)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 60,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": 61,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from PIL import Image\n",
        "from torch.optim import lr_scheduler\n",
        "import copy\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "plt.ion()"
      ],
      "outputs": [],
      "execution_count": 62,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/WawrzynP/Constellation_Classification/blob/master/DataSet_JPG.zip?raw=true -O DataSet_JPG.zip"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "--2022-01-13 22:31:18--  https://github.com/WawrzynP/Constellation_Classification/blob/master/DataSet_JPG.zip?raw=true\nResolving github.com (github.com)... 140.82.121.4\nConnecting to github.com (github.com)|140.82.121.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://github.com/WawrzynP/Constellation_Classification/raw/master/DataSet_JPG.zip [following]\n--2022-01-13 22:31:19--  https://github.com/WawrzynP/Constellation_Classification/raw/master/DataSet_JPG.zip\nReusing existing connection to github.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/WawrzynP/Constellation_Classification/master/DataSet_JPG.zip [following]\n--2022-01-13 22:31:19--  https://raw.githubusercontent.com/WawrzynP/Constellation_Classification/master/DataSet_JPG.zip\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 100009461 (95M) [application/zip]\nSaving to: ‘DataSet_JPG.zip’\n\nDataSet_JPG.zip     100%[===================>]  95.38M   250MB/s    in 0.4s    \n\n2022-01-13 22:31:24 (250 MB/s) - ‘DataSet_JPG.zip’ saved [100009461/100009461]\n\n"
        }
      ],
      "execution_count": 33,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip DataSet_JPG.zip"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Archive:  DataSet_JPG.zip\nreplace DataSet_JPG/Andromeda/img_1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "directory = 'DataSet_JPG'"
      ],
      "outputs": [],
      "execution_count": 63,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "image_size = 256"
      ],
      "outputs": [],
      "execution_count": 64,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "  [transforms.Resize([image_size, image_size]),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ])\n",
        "data = datasets.ImageFolder(root=directory, transform=transform)\n",
        "classNames = data.classes\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "outputs": [],
      "execution_count": 65,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_dataset(dataset, val_split=0.25):\n",
        "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
        "    datasets = {}\n",
        "    datasets['train'] = Subset(dataset, train_idx)\n",
        "    datasets['val'] = Subset(dataset, val_idx)\n",
        "    return datasets\n",
        "\n",
        "datasets = train_val_dataset(data)\n",
        "dataloaders = {x:DataLoader(datasets[x],32, shuffle=True, num_workers=4) for x in ['train','val']}\n",
        "x,y = next(iter(dataloaders['train']))"
      ],
      "outputs": [],
      "execution_count": 66,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val']}\n",
        "class_names = data.classes"
      ],
      "outputs": [],
      "execution_count": 67,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    val_acc_history = []\n",
        "    val_loss_history = []\n",
        "    train_acc_history = []\n",
        "    train_loss_history = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                \n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "                val_loss_history.append(epoch_loss)\n",
        "            if phase == 'train':\n",
        "                train_acc_history.append(epoch_acc)\n",
        "                train_loss_history.append(epoch_loss)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history, val_loss_history, train_acc_history, train_loss_history"
      ],
      "outputs": [],
      "execution_count": 68,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_acc_loss(val_acc_history, val_loss_history, train_acc_history, train_loss_history):\n",
        "  val_acc_hist = []\n",
        "  acc_hist = [h.cpu().numpy() for h in val_acc_history]\n",
        "  train_acc_hist = []\n",
        "  t_acc_hist = [h.cpu().numpy() for h in train_acc_history]\n",
        "  val_loss_history\n",
        "  num_epoch = 3\n",
        "\n",
        "  plt.figure(figsize=(12, 9))\n",
        "  plt.plot(\n",
        "          t_acc_hist, color='green', linestyle='-', \n",
        "          label='train accuracy')\n",
        "\n",
        "  plt.plot(\n",
        "          acc_hist, color='blue', linestyle='-', \n",
        "          label='validataion accuracy')\n",
        "  plt.title(\"Validation Accuracy\")\n",
        "  plt.xlabel(\"Training Epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(12, 9))\n",
        "  plt.plot(\n",
        "          train_loss_history, color='orange', linestyle='-', \n",
        "          label='train loss')\n",
        "  plt.plot(\n",
        "          val_loss_history, color='red', linestyle='-', \n",
        "          label='validataion loss')\n",
        "  plt.xlabel('Training Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "outputs": [],
      "execution_count": 69,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def conf_matrix(model, net_name):\n",
        "    model.eval()\n",
        "    confusion_matrix = torch.zeros(len(classNames), len(classNames))\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for l, p in zip(labels.view(-1), preds.view(-1)):\n",
        "              confusion_matrix[l.long(), p.long()] += 1\n",
        "\n",
        "        plt.figure(figsize = (20,20))\n",
        "        sn.heatmap(confusion_matrix, annot=True, cmap=\"Blues\", xticklabels=classNames, yticklabels=classNames)\n",
        "        plt.title('{name} \\nAccuracy:{num:.3f}'.format(name=net_name, num=np.trace(confusion_matrix)/2816), fontdict={'size':'21'})\n",
        "        plt.ylabel('Actual label', fontdict={'size':'18'})\n",
        "        plt.xlabel('Predicted label', fontdict={'size':'18'})\n",
        "        plt.show()"
      ],
      "outputs": [],
      "execution_count": 70,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet18"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft_rs18 = models.resnet18(pretrained=True)\n",
        "num_ft_rs18 = model_ft_rs18.fc.in_features\n",
        "model_ft_rs18.fc = nn.Linear(num_ft_rs18, len(classNames))\n",
        "model_ft_rs18 = model_ft_rs18.to(device)\n",
        "criterion_rs18 = nn.CrossEntropyLoss()\n",
        "optimizer_ft_rs18 = optim.SGD(model_ft_rs18.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler_rs18 = lr_scheduler.StepLR(optimizer_ft_rs18, step_size=7, gamma=0.1)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft_rs18, val_acc_history_rs18, val_loss_history_rs18, train_acc_history_rs18, train_loss_history_rs18 = train_model(model_ft_rs18, criterion_rs18, optimizer_ft_rs18, exp_lr_scheduler_rs18,\n",
        "                       num_epochs=25)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 0/24\n----------\ntrain Loss: 4.3049 Acc: 0.0452\nval Loss: 4.0317 Acc: 0.0753\n\nEpoch 1/24\n----------\ntrain Loss: 3.4363 Acc: 0.2197\nval Loss: 3.5326 Acc: 0.1722\n\nEpoch 2/24\n----------\ntrain Loss: 2.6344 Acc: 0.4039\nval Loss: 2.6876 Acc: 0.3714\n\nEpoch 3/24\n----------\ntrain Loss: 1.9851 Acc: 0.5606\nval Loss: 2.3311 Acc: 0.4464\n\nEpoch 4/24\n----------\ntrain Loss: 1.4925 Acc: 0.6709\nval Loss: 1.8824 Acc: 0.5476\n\nEpoch 5/24\n----------\ntrain Loss: 1.1166 Acc: 0.7563\nval Loss: 1.6585 Acc: 0.5877\n\nEpoch 6/24\n----------\ntrain Loss: 0.8355 Acc: 0.8196\nval Loss: 1.2688 Acc: 0.6722\n\nEpoch 7/24\n----------\ntrain Loss: 0.6142 Acc: 0.8930\nval Loss: 0.9446 Acc: 0.7532\n\nEpoch 8/24\n----------\ntrain Loss: 0.5731 Acc: 0.9061\nval Loss: 0.9364 Acc: 0.7532\n\nEpoch 9/24\n----------\ntrain Loss: 0.5544 Acc: 0.9106\nval Loss: 0.9177 Acc: 0.7582\n\nEpoch 10/24\n----------\ntrain Loss: 0.5324 Acc: 0.9167\nval Loss: 0.9153 Acc: 0.7550\n\nEpoch 11/24\n----------\ntrain Loss: 0.5108 Acc: 0.9241\nval Loss: 0.8948 Acc: 0.7656\n\nEpoch 12/24\n----------\ntrain Loss: 0.4958 Acc: 0.9265\nval Loss: 0.8852 Acc: 0.7635\n\nEpoch 13/24\n----------\ntrain Loss: 0.4821 Acc: 0.9281\nval Loss: 0.8874 Acc: 0.7628\n\nEpoch 14/24\n----------\ntrain Loss: 0.4591 Acc: 0.9367\nval Loss: 0.8670 Acc: 0.7663\n\nEpoch 15/24\n----------\ntrain Loss: 0.4602 Acc: 0.9360\nval Loss: 0.8682 Acc: 0.7706\n\nEpoch 16/24\n----------\ntrain Loss: 0.4646 Acc: 0.9331\nval Loss: 0.8706 Acc: 0.7653\n\nEpoch 17/24\n----------\ntrain Loss: 0.4561 Acc: 0.9361\nval Loss: 0.8696 Acc: 0.7681\n\nEpoch 18/24\n----------\ntrain Loss: 0.4609 Acc: 0.9349\nval Loss: 0.8653 Acc: 0.7678\n\nEpoch 19/24\n----------\ntrain Loss: 0.4539 Acc: 0.9368\nval Loss: 0.8691 Acc: 0.7674\n\nEpoch 20/24\n----------\ntrain Loss: 0.4565 Acc: 0.9388\nval Loss: 0.8622 Acc: 0.7670\n\nEpoch 21/24\n----------\ntrain Loss: 0.4526 Acc: 0.9380\nval Loss: 0.8569 Acc: 0.7710\n\nEpoch 22/24\n----------\ntrain Loss: 0.4564 Acc: 0.9357\nval Loss: 0.8650 Acc: 0.7678\n\nEpoch 23/24\n----------\ntrain Loss: 0.4512 Acc: 0.9395\nval Loss: 0.8634 Acc: 0.7656\n\nEpoch 24/24\n----------\ntrain Loss: 0.4534 Acc: 0.9366\nval Loss: 0.8652 Acc: 0.7713\n\nTraining complete in 67m 43s\nBest val Acc: 0.771307\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "scrolled": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix(model_ft_rs18, 'ResNet18')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc_loss(val_acc_history_rs18, val_loss_history_rs18, train_acc_history_rs18, train_loss_history_rs18)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet50"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft_rs50 = models.resnet50(pretrained=True)\n",
        "num_ft_rs50 = model_ft_rs50.fc.in_features\n",
        "\n",
        "model_ft_rs50.fc = nn.Linear(num_ft_rs50, len(classNames))\n",
        "\n",
        "model_ft_rs50 = model_ft_rs50.to(device)\n",
        "\n",
        "criterion_rs50 = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft_rs50 = optim.SGD(model_ft_rs50.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "exp_lr_scheduler_rs50 = lr_scheduler.StepLR(optimizer_ft_rs50, step_size=7, gamma=0.1)"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft_rs50, val_acc_history_rs50, val_loss_history_rs50, train_acc_history_rs50, train_loss_history_rs50 = train_model(model_ft_rs50, criterion_rs50, optimizer_ft_rs50, exp_lr_scheduler_rs50,\n",
        "                       num_epochs=25)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 0/24\n----------\ntrain Loss: 4.3059 Acc: 0.0478\nval Loss: 4.0532 Acc: 0.0774\n\nEpoch 1/24\n----------\ntrain Loss: 3.5070 Acc: 0.1931\nval Loss: 3.3143 Acc: 0.2077\n\nEpoch 2/24\n----------\ntrain Loss: 2.6475 Acc: 0.3642\nval Loss: 3.0324 Acc: 0.2553\n\nEpoch 3/24\n----------\ntrain Loss: 1.9188 Acc: 0.5368\nval Loss: 2.1667 Acc: 0.4368\n\nEpoch 4/24\n----------\ntrain Loss: 1.3606 Acc: 0.6612\nval Loss: 1.7813 Acc: 0.5252\n\nEpoch 5/24\n----------\ntrain Loss: 0.9572 Acc: 0.7620\nval Loss: 2.6735 Acc: 0.3782\n\nEpoch 6/24\n----------\ntrain Loss: 0.6638 Acc: 0.8355\nval Loss: 1.1640 Acc: 0.6538\n\nEpoch 7/24\n----------\ntrain Loss: 0.4445 Acc: 0.9096\nval Loss: 0.7494 Acc: 0.7695\n\nEpoch 8/24\n----------\ntrain Loss: 0.4021 Acc: 0.9258\nval Loss: 0.7350 Acc: 0.7759\n\nEpoch 9/24\n----------\ntrain Loss: 0.3723 Acc: 0.9325\nval Loss: 0.7269 Acc: 0.7752\n\nEpoch 10/24\n----------\ntrain Loss: 0.3552 Acc: 0.9411\nval Loss: 0.7201 Acc: 0.7720\n\nEpoch 11/24\n----------\ntrain Loss: 0.3317 Acc: 0.9446\nval Loss: 0.7047 Acc: 0.7820\n\nEpoch 12/24\n----------\ntrain Loss: 0.3175 Acc: 0.9476\nval Loss: 0.7047 Acc: 0.7820\n\nEpoch 13/24\n----------\ntrain Loss: 0.3078 Acc: 0.9513\nval Loss: 0.6922 Acc: 0.7781\n\nEpoch 14/24\n----------\ntrain Loss: 0.2939 Acc: 0.9579\nval Loss: 0.6855 Acc: 0.7809\n\nEpoch 15/24\n----------\ntrain Loss: 0.2916 Acc: 0.9570\nval Loss: 0.6917 Acc: 0.7823\n\nEpoch 16/24\n----------\ntrain Loss: 0.2939 Acc: 0.9562\nval Loss: 0.6852 Acc: 0.7855\n\nEpoch 17/24\n----------\ntrain Loss: 0.2852 Acc: 0.9579\nval Loss: 0.6923 Acc: 0.7852\n\nEpoch 18/24\n----------\ntrain Loss: 0.2878 Acc: 0.9580\nval Loss: 0.6901 Acc: 0.7802\n\nEpoch 19/24\n----------\ntrain Loss: 0.2845 Acc: 0.9626\nval Loss: 0.6878 Acc: 0.7805\n\nEpoch 20/24\n----------\ntrain Loss: 0.2863 Acc: 0.9581\nval Loss: 0.6842 Acc: 0.7827\n\nEpoch 21/24\n----------\ntrain Loss: 0.2847 Acc: 0.9615\nval Loss: 0.6866 Acc: 0.7809\n\nEpoch 22/24\n----------\ntrain Loss: 0.2803 Acc: 0.9601\nval Loss: 0.6852 Acc: 0.7816\n\nEpoch 23/24\n----------\ntrain Loss: 0.2842 Acc: 0.9601\nval Loss: 0.6903 Acc: 0.7820\n\nEpoch 24/24\n----------\ntrain Loss: 0.2823 Acc: 0.9590\nval Loss: 0.6824 Acc: 0.7827\n\nTraining complete in 110m 12s\nBest val Acc: 0.785511\n"
        }
      ],
      "execution_count": 44,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix(model_ft_rs50, 'ResNet50')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc_loss(val_acc_history_rs50, val_loss_history_rs50, train_acc_history_rs50, train_loss_history_rs50)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet101"
      ],
      "outputs": [],
      "execution_count": 71,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft_rs101 = models.resnet101(pretrained=True)\n",
        "num_ft_rs101 = model_ft_rs101.fc.in_features\n",
        "\n",
        "model_ft_rs101.fc = nn.Linear(num_ft_rs101, len(classNames))\n",
        "\n",
        "model_ft_rs101 = model_ft_rs101.to(device)\n",
        "\n",
        "criterion_rs101 = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft_rs101 = optim.SGD(model_ft_rs101.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "exp_lr_scheduler_rs101 = lr_scheduler.StepLR(optimizer_ft_rs101, step_size=7, gamma=0.1)"
      ],
      "outputs": [],
      "execution_count": 72,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft_rs101, val_acc_history_rs101, val_loss_history_rs101, train_acc_history_rs101, train_loss_history_rs101= train_model(model_ft_rs101, criterion_rs101, optimizer_ft_rs101, exp_lr_scheduler_rs101,\n",
        "                       num_epochs=25)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 0/24\n----------\ntrain Loss: 0.1846 Acc: 0.9762\nval Loss: 0.6108 Acc: 0.8022\n\nEpoch 1/24\n----------\ntrain Loss: 0.1787 Acc: 0.9768\nval Loss: 0.6081 Acc: 0.8001\n\nEpoch 2/24\n----------\ntrain Loss: 0.1796 Acc: 0.9773\nval Loss: 0.6020 Acc: 0.8029\n\nEpoch 3/24\n----------\ntrain Loss: 0.1831 Acc: 0.9774\nval Loss: 0.6008 Acc: 0.8058\n\nEpoch 4/24\n----------\ntrain Loss: 0.1828 Acc: 0.9760\nval Loss: 0.6071 Acc: 0.8029\n\nEpoch 5/24\n----------\ntrain Loss: 0.1813 Acc: 0.9749\nval Loss: 0.5998 Acc: 0.8058\n\nEpoch 6/24\n----------\ntrain Loss: 0.1812 Acc: 0.9767\nval Loss: 0.6047 Acc: 0.8068\n\nEpoch 7/24\n----------\ntrain Loss: 0.1795 Acc: 0.9762\nval Loss: 0.6019 Acc: 0.8050\n\nEpoch 8/24\n----------\ntrain Loss: 0.1782 Acc: 0.9774\nval Loss: 0.6055 Acc: 0.8008\n\nEpoch 9/24\n----------\ntrain Loss: 0.1789 Acc: 0.9782\nval Loss: 0.6049 Acc: 0.8004\n\nEpoch 10/24\n----------\ntrain Loss: 0.1804 Acc: 0.9768\nval Loss: 0.6074 Acc: 0.8054\n\nEpoch 11/24\n----------\ntrain Loss: 0.1797 Acc: 0.9766\nval Loss: 0.6034 Acc: 0.7987\n\nEpoch 12/24\n----------\ntrain Loss: 0.1793 Acc: 0.9790\nval Loss: 0.6026 Acc: 0.8040\n\nEpoch 13/24\n----------\ntrain Loss: 0.1802 Acc: 0.9775\nval Loss: 0.6114 Acc: 0.8008\n\nEpoch 14/24\n----------\ntrain Loss: 0.1798 Acc: 0.9769\nval Loss: 0.6002 Acc: 0.8072\n\nEpoch 15/24\n----------\ntrain Loss: 0.1805 Acc: 0.9777\nval Loss: 0.6044 Acc: 0.8043\n\nEpoch 16/24\n----------\ntrain Loss: 0.1831 Acc: 0.9786\nval Loss: 0.6032 Acc: 0.7997\n\nEpoch 17/24\n----------\ntrain Loss: 0.1818 Acc: 0.9770\nval Loss: 0.6078 Acc: 0.8022\n\nEpoch 18/24\n----------\ntrain Loss: 0.1823 Acc: 0.9779\nval Loss: 0.6043 Acc: 0.8047\n\nEpoch 19/24\n----------\ntrain Loss: 0.1850 Acc: 0.9760\nval Loss: 0.6078 Acc: 0.8015\n\nEpoch 20/24\n----------\ntrain Loss: 0.1820 Acc: 0.9772\nval Loss: 0.6068 Acc: 0.8036\n\nEpoch 21/24\n----------\ntrain Loss: 0.1817 Acc: 0.9766\nval Loss: 0.6046 Acc: 0.8022\n\nEpoch 22/24\n----------\ntrain Loss: 0.1810 Acc: 0.9767\nval Loss: 0.6068 Acc: 0.8029\n\nEpoch 23/24\n----------\ntrain Loss: 0.1788 Acc: 0.9779\nval Loss: 0.6017 Acc: 0.8054\n\nEpoch 24/24\n----------\ntrain Loss: 0.1785 Acc: 0.9769\nval Loss: 0.6073 Acc: 0.8036\n\nTraining complete in 166m 50s\nBest val Acc: 0.807173\n"
        }
      ],
      "execution_count": 74,
      "metadata": {
        "gather": {
          "logged": 1642163410783
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix(model_ft_rs101, 'ResNet101')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc_loss(val_acc_history_rs101, val_loss_history_rs101, train_acc_history_rs101, train_loss_history_rs101)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG11"
      ],
      "outputs": [],
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1642163980724
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft_vgg11 = models.vgg11_bn(pretrained=True)\n",
        "num_ft_vgg11 = model_ft_vgg11.classifier[6].in_features\n",
        "model_ft_vgg11.classifier[6] = nn.Linear(num_ft_vgg11, len(classNames))\n",
        "\n",
        "model_ft_vgg11 = model_ft_vgg11.to(device)\n",
        "criterion_vgg11 = nn.CrossEntropyLoss()\n",
        "optimizer_ft_vgg11 = optim.SGD(model_ft_vgg11.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "exp_lr_scheduler_vgg11 = lr_scheduler.StepLR(optimizer_ft_vgg11, step_size=7, gamma=0.1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Downloading: \"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\" to /home/azureuser/.cache/torch/hub/checkpoints/vgg11_bn-6002323d.pth\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0.00/507M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad1137a89fd74757bfd04e639a638fe8"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 76,
      "metadata": {
        "gather": {
          "logged": 1642164003063
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft_vgg11, val_acc_history_vgg11, val_loss_history_vgg11, train_acc_history_vgg11, train_loss_history_vgg11= train_model(model_ft_vgg11, criterion_vgg11, optimizer_ft_vgg11, exp_lr_scheduler_vgg11,\n",
        "                       num_epochs=25)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 0/24\n----------\ntrain Loss: 4.1898 Acc: 0.0586\nval Loss: 3.7159 Acc: 0.1346\n\nEpoch 1/24\n----------\ntrain Loss: 3.2505 Acc: 0.1972\nval Loss: 2.8029 Acc: 0.2898\n\nEpoch 2/24\n----------\ntrain Loss: 2.4311 Acc: 0.3572\nval Loss: 2.3278 Acc: 0.3761\n\nEpoch 3/24\n----------\ntrain Loss: 1.8696 Acc: 0.4859\nval Loss: 1.8539 Acc: 0.4648\n\nEpoch 4/24\n----------\ntrain Loss: 1.4496 Acc: 0.5889\nval Loss: 1.4900 Acc: 0.5604\n\nEpoch 5/24\n----------\ntrain Loss: 1.1428 Acc: 0.6628\nval Loss: 1.4194 Acc: 0.5820\n\nEpoch 6/24\n----------\ntrain Loss: 0.8906 Acc: 0.7337\nval Loss: 1.3274 Acc: 0.6097\n\nEpoch 7/24\n----------\ntrain Loss: 0.5821 Acc: 0.8280\nval Loss: 0.9239 Acc: 0.7081\n\nEpoch 8/24\n----------\ntrain Loss: 0.5053 Acc: 0.8518\nval Loss: 0.9039 Acc: 0.7138\n\nEpoch 9/24\n----------\ntrain Loss: 0.4758 Acc: 0.8552\nval Loss: 0.8911 Acc: 0.7166\n\nEpoch 10/24\n----------\ntrain Loss: 0.4619 Acc: 0.8658\nval Loss: 0.8816 Acc: 0.7195\n\nEpoch 11/24\n----------\ntrain Loss: 0.4320 Acc: 0.8723\nval Loss: 0.8775 Acc: 0.7209\n\nEpoch 12/24\n----------\ntrain Loss: 0.4151 Acc: 0.8791\nval Loss: 0.8756 Acc: 0.7177\n\nEpoch 13/24\n----------\ntrain Loss: 0.3927 Acc: 0.8878\nval Loss: 0.8647 Acc: 0.7259\n\nEpoch 14/24\n----------\ntrain Loss: 0.3705 Acc: 0.8920\nval Loss: 0.8577 Acc: 0.7290\n\nEpoch 15/24\n----------\ntrain Loss: 0.3626 Acc: 0.8928\nval Loss: 0.8537 Acc: 0.7269\n\nEpoch 16/24\n----------\ntrain Loss: 0.3611 Acc: 0.8911\nval Loss: 0.8527 Acc: 0.7287\n\nEpoch 17/24\n----------\ntrain Loss: 0.3512 Acc: 0.9000\nval Loss: 0.8533 Acc: 0.7305\n\nEpoch 18/24\n----------\ntrain Loss: 0.3503 Acc: 0.8990\nval Loss: 0.8565 Acc: 0.7248\n\nEpoch 19/24\n----------\ntrain Loss: 0.3542 Acc: 0.8991\nval Loss: 0.8503 Acc: 0.7287\n\nEpoch 20/24\n----------\ntrain Loss: 0.3431 Acc: 0.9040\nval Loss: 0.8521 Acc: 0.7276\n\nEpoch 21/24\n----------\ntrain Loss: 0.3478 Acc: 0.9000\nval Loss: 0.8458 Acc: 0.7319\n\nEpoch 22/24\n----------\ntrain Loss: 0.3444 Acc: 0.9013\nval Loss: 0.8519 Acc: 0.7294\n\nEpoch 23/24\n----------\ntrain Loss: 0.3506 Acc: 0.9000\nval Loss: 0.8479 Acc: 0.7298\n\nEpoch 24/24\n----------\ntrain Loss: 0.3452 Acc: 0.9044\nval Loss: 0.8487 Acc: 0.7283\n\nTraining complete in 90m 51s\nBest val Acc: 0.731889\n"
        }
      ],
      "execution_count": 77,
      "metadata": {
        "gather": {
          "logged": 1642169453695
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix(model_ft_vgg11, 'VGG11')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc_loss(val_acc_history_vgg11, val_loss_history_vgg11, train_acc_history_vgg11, train_loss_history_vgg11)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Densenet121"
      ],
      "outputs": [],
      "execution_count": 78,
      "metadata": {
        "gather": {
          "logged": 1642169630991
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft_ds121 = models.densenet121(pretrained=True)\n",
        "num_ft_ds121 = model_ft_ds121.classifier.in_features\n",
        "model_ft_ds121.classifier = nn.Linear(num_ft_ds121, len(classNames))\n",
        "\n",
        "model_ft_ds121 = model_ft_ds121.to(device)\n",
        "criterion_ds121 = nn.CrossEntropyLoss()\n",
        "optimizer_ft_ds121 = optim.SGD(model_ft_ds121.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler_ds121 = lr_scheduler.StepLR(optimizer_ft_ds121, step_size=7, gamma=0.1)"
      ],
      "outputs": [],
      "execution_count": 79,
      "metadata": {
        "gather": {
          "logged": 1642169632562
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft_ds121, val_acc_history_ds121, val_loss_history_ds121, train_acc_history_ds121, train_loss_history_ds121= train_model(model_ft_ds121, criterion_ds121, optimizer_ft_ds121, exp_lr_scheduler_ds121,\n",
        "                       num_epochs=25)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 0/24\n----------\ntrain Loss: 4.3411 Acc: 0.0425\nval Loss: 4.0306 Acc: 0.0987\n\nEpoch 1/24\n----------\ntrain Loss: 3.5070 Acc: 0.1937\nval Loss: 3.2139 Acc: 0.2319\n\nEpoch 2/24\n----------\ntrain Loss: 2.5754 Acc: 0.4009\nval Loss: 2.2321 Acc: 0.4549\n\nEpoch 3/24\n----------\ntrain Loss: 1.8507 Acc: 0.5585\nval Loss: 2.1575 Acc: 0.4659\n\nEpoch 4/24\n----------\ntrain Loss: 1.3448 Acc: 0.6694\nval Loss: 1.6010 Acc: 0.5774\n\nEpoch 5/24\n----------\ntrain Loss: 0.9619 Acc: 0.7595\nval Loss: 0.9813 Acc: 0.7230\n\nEpoch 6/24\n----------\ntrain Loss: 0.7093 Acc: 0.8213\nval Loss: 0.9813 Acc: 0.7120\n\nEpoch 7/24\n----------\ntrain Loss: 0.4878 Acc: 0.8949\nval Loss: 0.7107 Acc: 0.7798\n\nEpoch 8/24\n----------\ntrain Loss: 0.4355 Acc: 0.9134\nval Loss: 0.6901 Acc: 0.7855\n\nEpoch 9/24\n----------\ntrain Loss: 0.4106 Acc: 0.9214\nval Loss: 0.6840 Acc: 0.7820\n\nEpoch 10/24\n----------\ntrain Loss: 0.3859 Acc: 0.9279\nval Loss: 0.6624 Acc: 0.7923\n\nEpoch 11/24\n----------\ntrain Loss: 0.3738 Acc: 0.9319\nval Loss: 0.6531 Acc: 0.7969\n\nEpoch 12/24\n----------\ntrain Loss: 0.3490 Acc: 0.9394\nval Loss: 0.6457 Acc: 0.7965\n\nEpoch 13/24\n----------\ntrain Loss: 0.3382 Acc: 0.9405\nval Loss: 0.6453 Acc: 0.7955\n\nEpoch 14/24\n----------\ntrain Loss: 0.3222 Acc: 0.9485\nval Loss: 0.6413 Acc: 0.7915\n\nEpoch 15/24\n----------\ntrain Loss: 0.3215 Acc: 0.9478\nval Loss: 0.6411 Acc: 0.7944\n\nEpoch 16/24\n----------\ntrain Loss: 0.3181 Acc: 0.9472\nval Loss: 0.6382 Acc: 0.7958\n\nEpoch 17/24\n----------\ntrain Loss: 0.3196 Acc: 0.9470\nval Loss: 0.6371 Acc: 0.7965\n\nEpoch 18/24\n----------\ntrain Loss: 0.3161 Acc: 0.9487\nval Loss: 0.6301 Acc: 0.7990\n\nEpoch 19/24\n----------\ntrain Loss: 0.3139 Acc: 0.9515\nval Loss: 0.6297 Acc: 0.7979\n\nEpoch 20/24\n----------\ntrain Loss: 0.3127 Acc: 0.9492\nval Loss: 0.6380 Acc: 0.7955\n\nEpoch 21/24\n----------\ntrain Loss: 0.3100 Acc: 0.9497\nval Loss: 0.6353 Acc: 0.7958\n\nEpoch 22/24\n----------\ntrain Loss: 0.3107 Acc: 0.9493\nval Loss: 0.6345 Acc: 0.7965\n\nEpoch 23/24\n----------\ntrain Loss: 0.3094 Acc: 0.9491\nval Loss: 0.6321 Acc: 0.7987\n\nEpoch 24/24\n----------\ntrain Loss: 0.3163 Acc: 0.9486\nval Loss: 0.6353 Acc: 0.7933\n\nTraining complete in 119m 52s\nBest val Acc: 0.799006\n"
        }
      ],
      "execution_count": 80,
      "metadata": {
        "gather": {
          "logged": 1642176826721
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix(model_ft_ds121, 'Densenet')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc_loss(val_acc_history_ds121, val_loss_history_ds121, train_acc_history_ds121, train_loss_history_ds121)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Squeezenet"
      ],
      "outputs": [],
      "execution_count": 81,
      "metadata": {
        "gather": {
          "logged": 1642179769945
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft_sqn = models.squeezenet1_0(pretrained=True)\n",
        "model_ft_sqn.classifier[1] = nn.Conv2d(512, len(classNames), kernel_size=(1,1), stride=(1,1))\n",
        "model_ft_sqn.num_classes = len(classNames)\n",
        "\n",
        "model_ft_sqn = model_ft_sqn.to(device)\n",
        "criterion_sqn = nn.CrossEntropyLoss()\n",
        "optimizer_ft_sqn = optim.SGD(model_ft_sqn.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler_sqn = lr_scheduler.StepLR(optimizer_ft_sqn, step_size=7, gamma=0.1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Downloading: \"https://download.pytorch.org/models/squeezenet1_0-a815701f.pth\" to /home/azureuser/.cache/torch/hub/checkpoints/squeezenet1_0-a815701f.pth\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0.00/4.79M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e26980b79ee44f7d84d84b5016885fd2"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 82,
      "metadata": {
        "gather": {
          "logged": 1642179772083
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft_sqn, val_acc_history_sqn, val_loss_history_sqn, train_acc_history_sqn, train_loss_history_sqn = train_model(model_ft_sqn, criterion_sqn, optimizer_ft_sqn, exp_lr_scheduler_sqn,\n",
        "                       num_epochs=25)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 0/24\n----------\ntrain Loss: 4.4559 Acc: 0.0144\nval Loss: 4.4459 Acc: 0.0163\n\nEpoch 1/24\n----------\ntrain Loss: 4.3568 Acc: 0.0256\nval Loss: 4.2672 Acc: 0.0437\n\nEpoch 2/24\n----------\ntrain Loss: 4.1881 Acc: 0.0476\nval Loss: 4.2067 Acc: 0.0455\n\nEpoch 3/24\n----------\ntrain Loss: 4.0090 Acc: 0.0723\nval Loss: 3.8685 Acc: 0.1143\n\nEpoch 4/24\n----------\ntrain Loss: 3.7288 Acc: 0.1143\nval Loss: 3.5847 Acc: 0.1420\n\nEpoch 5/24\n----------\ntrain Loss: 3.4085 Acc: 0.1636\nval Loss: 3.2739 Acc: 0.1946\n\nEpoch 6/24\n----------\ntrain Loss: 3.1159 Acc: 0.2205\nval Loss: 3.0407 Acc: 0.2436\n\nEpoch 7/24\n----------\ntrain Loss: 2.5089 Acc: 0.3471\nval Loss: 2.3846 Acc: 0.3647\n\nEpoch 8/24\n----------\ntrain Loss: 2.3209 Acc: 0.3899\nval Loss: 2.3257 Acc: 0.3796\n\nEpoch 9/24\n----------\ntrain Loss: 2.2294 Acc: 0.4041\nval Loss: 2.2545 Acc: 0.3970\n\nEpoch 10/24\n----------\ntrain Loss: 2.1801 Acc: 0.4231\nval Loss: 2.1730 Acc: 0.4155\n\nEpoch 11/24\n----------\ntrain Loss: 2.0957 Acc: 0.4369\nval Loss: 2.1574 Acc: 0.4041\n\nEpoch 12/24\n----------\ntrain Loss: 2.0385 Acc: 0.4528\nval Loss: 2.0809 Acc: 0.4474\n\nEpoch 13/24\n----------\ntrain Loss: 1.9720 Acc: 0.4643\nval Loss: 2.0628 Acc: 0.4329\n\nEpoch 14/24\n----------\ntrain Loss: 1.8225 Acc: 0.5017\nval Loss: 1.9252 Acc: 0.4702\n\nEpoch 15/24\n----------\ntrain Loss: 1.7991 Acc: 0.5022\nval Loss: 1.8994 Acc: 0.4819\n\nEpoch 16/24\n----------\ntrain Loss: 1.7856 Acc: 0.5051\nval Loss: 1.9076 Acc: 0.4748\n\nEpoch 17/24\n----------\ntrain Loss: 1.7873 Acc: 0.5080\nval Loss: 1.8908 Acc: 0.4741\n\nEpoch 18/24\n----------\ntrain Loss: 1.7698 Acc: 0.5208\nval Loss: 1.8859 Acc: 0.4833\n\nEpoch 19/24\n----------\ntrain Loss: 1.7623 Acc: 0.5148\nval Loss: 1.8765 Acc: 0.4858\n\nEpoch 20/24\n----------\ntrain Loss: 1.7518 Acc: 0.5149\nval Loss: 1.8835 Acc: 0.4798\n\nEpoch 21/24\n----------\ntrain Loss: 1.7450 Acc: 0.5228\nval Loss: 1.8646 Acc: 0.4883\n\nEpoch 22/24\n----------\ntrain Loss: 1.7369 Acc: 0.5241\nval Loss: 1.8641 Acc: 0.4858\n\nEpoch 23/24\n----------\ntrain Loss: 1.7423 Acc: 0.5200\nval Loss: 1.8630 Acc: 0.4862\n\nEpoch 24/24\n----------\ntrain Loss: 1.7244 Acc: 0.5296\nval Loss: 1.8631 Acc: 0.4883\n\nTraining complete in 62m 42s\nBest val Acc: 0.488281\n"
        }
      ],
      "execution_count": 83,
      "metadata": {
        "gather": {
          "logged": 1642183536247
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix(model_ft_sqn, 'Squeezenet')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc_loss(val_acc_history_sqn, val_loss_history_sqn, train_acc_history_sqn, train_loss_history_sqn)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}